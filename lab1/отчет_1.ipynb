{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d352ad",
   "metadata": {},
   "source": [
    "#### 1. Создайте python-скрипт (**data_creation.py**), который создает различные наборы данных, описывающие некий процесс (например, изменение дневной температуры). Таких наборов должно быть несколько, в некоторые данные можно включить аномалии или шумы. Часть наборов данных должны быть сохранены в папке “train”, другая часть в папке “test”.\n",
    "\n",
    "- Буду генерить годовые температуры.\n",
    "- Опишу каждый сезон трендом, средней температурой и аплитудой. \n",
    "- точки созам синусоидой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_creation.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def create_sin_params(season: int, amplitude_temp: float = 20):\n",
    "    # Базовые средние температуры для каждого сезона (при amplitude_temp = 20)\n",
    "    base_avg_temps = {\n",
    "        1: 20,   # лето\n",
    "        2: 10,   # осень\n",
    "        3: -5,   # зима\n",
    "        4: 8     # весна\n",
    "    }\n",
    "    # Коэффициенты амплитуды (относительно базовой amplitude_temp = 20)\n",
    "    amp_factors = {\n",
    "        1: 1.0,  # летом колебания +-10 при amplitude_temp=20 -> амплитуда = 10\n",
    "        2: 0.8,\n",
    "        3: 0.6, # зимой - наименьшие\n",
    "        4: 0.9\n",
    "    }\n",
    "    # Тренд: -1 = охлаждение, +1 = потепление\n",
    "    trends = {1: -1, 2: -1, 3: 1, 4: 1}\n",
    "    start_months = {1: 6, 2: 9, 3: 12, 4: 3}\n",
    "    days = {1: 92, 2: 91, 3: 90, 4: 92} # 365\n",
    "\n",
    "    if season not in base_avg_temps:\n",
    "        raise ValueError(\"Сезон должен быть от 1 до 4\")\n",
    "\n",
    "    avg_temp = base_avg_temps[season]\n",
    "    amplitude = amplitude_temp * amp_factors[season] / 2  # делим на 2, чтобы amplitude_temp был полным размахом\n",
    "    trend = trends[season]\n",
    "    start_month = start_months[season]\n",
    "    total_days = days[season]\n",
    "\n",
    "    return start_month, avg_temp, amplitude, trend, total_days\n",
    "\n",
    "\n",
    "def create_sin(season_params):\n",
    "    start_month, avg_temp, peak_temp, trend, total_days = season_params\n",
    "    amplitude = abs(peak_temp - avg_temp)\n",
    "    hours = total_days * 24\n",
    "    t = np.linspace(0, total_days, hours)\n",
    "\n",
    "    temp_base = avg_temp + amplitude * np.sin(2 * np.pi * t / total_days + np.pi / 2)\n",
    "\n",
    "    # температура повышается на 0,3 от total_days\n",
    "    if trend != 0:\n",
    "        trend_factor = (peak_temp - avg_temp) * 0.3 * trend * (t / total_days)\n",
    "        temp_base += trend_factor\n",
    "\n",
    "    start_date = datetime(year=2023, month=start_month, day=1)\n",
    "    dates = [start_date + timedelta(hours=i) for i in range(hours)]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'day_of_month': [d.day for d in dates],\n",
    "        'month': [d.month for d in dates],\n",
    "        'hour': [d.hour for d in dates],\n",
    "        'temperature': temp_base\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_noise(df: pd.DataFrame, noise_amplitude_percent: float = 10.0):\n",
    "    temp_range = df['temperature'].max() - df['temperature'].min()\n",
    "    if temp_range == 0:\n",
    "        temp_range = 1.0  # избежать деления на ноль\n",
    "    noise_std = (noise_amplitude_percent / 100.0) * temp_range\n",
    "    noise = np.random.normal(0, noise_std, size=len(df))\n",
    "    df['temperature'] = df['temperature'] + noise\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_anomaly(df: pd.DataFrame, anomaly_type='multi_day'):\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "\n",
    "    if anomaly_type == 'multi_day':\n",
    "        duration = np.random.randint(72, 169)  # 3–7 дней\n",
    "        start_idx = np.random.randint(0, max(1, n - duration))\n",
    "        shift = np.random.choice([-10, 10])\n",
    "        df.iloc[start_idx:start_idx + duration, df.columns.get_loc('temperature')] += shift\n",
    "\n",
    "    elif anomaly_type == 'intraday':\n",
    "        day_start = np.random.randint(0, n // 24) * 24\n",
    "        if day_start + 24 > n:\n",
    "            day_start = n - 24\n",
    "        spike_duration = np.random.randint(2, 7)\n",
    "        spike_start = day_start + np.random.randint(0, 24 - spike_duration)\n",
    "        spike_temp = np.random.uniform(15, 25)\n",
    "        df.iloc[spike_start:spike_start + spike_duration, df.columns.get_loc('temperature')] += spike_temp\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_seasons_temp(amplitude_temp: float = 20.0, noise_amplitude_percent: float = 10.0):\n",
    "    # \n",
    "    all_data = []\n",
    "    for season in [1, 2, 3, 4]:\n",
    "        params = create_sin_params(season, amplitude_temp)\n",
    "        df = create_sin(params)\n",
    "        df = create_noise(df, noise_amplitude_percent)\n",
    "\n",
    "        # С вероятностью 50% добавляем аномалию\n",
    "        if np.random.rand() < 0.5:\n",
    "            anomaly_type = np.random.choice(['multi_day', 'intraday'])\n",
    "            df = create_anomaly(df, anomaly_type=anomaly_type)\n",
    "\n",
    "        # Добавляем метку сезона для прозрачности (опционально)\n",
    "        df['season'] = season\n",
    "        all_data.append(df)\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# генерит данные за год почасово по синусоиде по 4м сезонам, перемешивает и делит на тест/трен\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Генерация данных температуры по сезонам\")\n",
    "    parser.add_argument('--amplitude_temp', type=int, default=20,\n",
    "                        help='Базовая амплитуда температуры (резерв)')\n",
    "    parser.add_argument('--noise_amplitude_percent', type=int, default=10,\n",
    "                        help='Амплитуда шума в процентах от диапазона температуры (0–40)')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not (0 <= args.noise_amplitude_percent <= 40):\n",
    "        raise ValueError(\"Амплитуда шума должна быть в диапазоне 0–40%\")\n",
    "\n",
    "    train_dir = f'data_gen/data_{args.noise_amplitude_percent}_{args.amplitude_temp}/train'\n",
    "    test_dir = f'data_gen/data_{args.noise_amplitude_percent}_{args.amplitude_temp}/test'\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Генерируем все данные\n",
    "    full_data = create_seasons_temp(\n",
    "        amplitude_temp=args.amplitude_temp,\n",
    "        noise_amplitude_percent=args.noise_amplitude_percent\n",
    "    )\n",
    "\n",
    "    # Убедимся, что порядок случайный\n",
    "    full_data = full_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Разделяем: 70% → train, 30% → test\n",
    "    split_idx = int(0.7 * len(full_data))\n",
    "    train_data = full_data.iloc[:split_idx]\n",
    "    test_data = full_data.iloc[split_idx:]\n",
    "\n",
    "    # Сохраняем\n",
    "    train_data.to_csv(os.path.join(train_dir, 'data.csv'), index=False)\n",
    "    test_data.to_csv(os.path.join(test_dir, 'data.csv'), index=False)\n",
    "\n",
    "    print(f\"Данные успешно сохранены:\")\n",
    "    print(f\"  train/data.csv: {len(train_data)} записей\")\n",
    "    print(f\"  test/data.csv:  {len(test_data)} записей\")\n",
    "    print(f\"  Всего: {len(full_data)} записей (по ~90 дней × 24 часа × 4 сезона)\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bf085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/t4nner/.venv311/lib64/python3.11/site-packages (from -r requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: numpy in /home/t4nner/.venv311/lib64/python3.11/site-packages (from -r requirements.txt (line 2)) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/t4nner/.venv311/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/t4nner/.venv311/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/t4nner/.venv311/lib64/python3.11/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/t4nner/.venv311/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Данные успешно сохранены:\n",
      "  train/data.csv: 6132 записей\n",
      "  test/data.csv:  2628 записей\n",
      "  Всего: 8760 записей (по ~90 дней × 24 часа × 4 сезона)\n",
      "Данные успешно сохранены:\n",
      "  train/data.csv: 6132 записей\n",
      "  test/data.csv:  2628 записей\n",
      "  Всего: 8760 записей (по ~90 дней × 24 часа × 4 сезона)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python data_creation.py\n",
    "!python data_creation.py --amplitude_temp 15 --noise_amplitude_percent 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2319586",
   "metadata": {},
   "source": [
    "Данные разделены и сохранены (раздельно а не как указано в задании) раздельно чтобы сохранять однородность (train/test). Потом объединю."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dca56",
   "metadata": {},
   "source": [
    "### 2. создайте python-скрипт (**data_preprocessing.py**), который выполняет предобработку данных, например, с помощью sklearn.preprocessing.StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d425f05",
   "metadata": {},
   "source": [
    "- объединяю данные\n",
    "- тренирую standardScaler на train выборке\n",
    "- обрабатываю данные и сохраняю вместе с параметрами standardScaler\n",
    "\n",
    "**я добавил source в датасет чтобы можно было по нему фильтровать если будет плохой результат (или нужно будет отследить влияние шума на прогноз если обучать с меньшим шумом)**\n",
    "\n",
    "[см. файл обработки](./data_preprocessing.py)\n",
    "```\n",
    "(.venv311) ➜  lab1 python data_preprocessing.py \n",
    "Найдено тренировочных файлов: 2\n",
    "Найдено тестовых файлов: 2\n",
    "Объединено записей в train: 12264\n",
    "Объединено записей в test:  5256\n",
    "Сохранено:\n",
    "  - Тренировочные данные: data/preprocessed_data_train.csv (12264 записей)\n",
    "  - Тестовые данные:      data/preprocessed_data_test.csv (5256 записей)\n",
    "  - Параметры StandardScaler:    data/scaler_*.npy\n",
    "\n",
    "Столбцы в данных: ['day_of_month', 'month', 'hour', 'temperature', 'season', 'source']\n",
    "Масштабированные признаки: ['day_of_month', 'month', 'hour', 'season']\n",
    "Целевая переменная: temperature\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python data_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbeee62",
   "metadata": {},
   "source": [
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09953e3",
   "metadata": {},
   "source": [
    "### 3. создайте python-скрипт (**model_preparation.py**), который создает и обучает модель машинного обучения на построенных данных из папки “train” (lab1/data/preprocessed_data_train.csv)\n",
    "\n",
    "- проверка переменных\n",
    "- обучение модели\n",
    "- Оценка качества\n",
    "- [model_preparation.py](model_preparation.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c89278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python ./model_preparation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e965026",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Вывод</b></summary>\n",
    "\n",
    "```\n",
    "(.venv311) ➜  lab1 python ./model_preparation.py\n",
    "Загрузка тренировочных данных из: data/preprocessed_data_train.csv\n",
    "Загрузка тестовых данных из: data/preprocessed_data_test.csv\n",
    "\n",
    "Размер данных:\n",
    "   Тренировочные: 12264 записей\n",
    "   Тестовые:      5256 записей\n",
    "   Признаки: ['day_of_month', 'month', 'hour', 'season']\n",
    "   Целевая переменная: temperature\n",
    "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
    "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
    "Обучение завершено за 0:00:00.439171\n",
    "\n",
    "Модель сохранена: models/RandomForestRegressor_20251103_201232.joblib\n",
    "\\Метаданные сохранены: models/metadata_20251103_201232.json\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c27502",
   "metadata": {},
   "source": [
    "#### 4. создайте python-скрипт (model_testing.py), проверяющий модель машинного обучения на построенных данных из папки “test”.\n",
    "\n",
    "- загружаю последнюю модель если она не указана\n",
    "- анализ:\n",
    "- - Метрики качества: MSE        | MAE        | R2\n",
    "- Визуализация опциональна\n",
    "\n",
    "<details>\n",
    "    <summary><b>Вывод</b></summary>\n",
    "\n",
    "```\n",
    "(.venv311) ➜  lab1 python model_testing.py\n",
    "Автоматически выбран последний файл метаданных: models/metadata_20251103_201232.json\n",
    "\n",
    "Загружаем модель из models/RandomForestRegressor_20251103_201232.joblib\n",
    "Тренировочные данные из data/preprocessed_data_train.csv\n",
    "Тестовые данные из data/preprocessed_data_test.csv\n",
    "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
    "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
    "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
    "\n",
    "==================================================\n",
    "РЕЗУЛЬТАТЫ ТЕСТИРОВАНИЯ МОДЕЛИ\n",
    "==================================================\n",
    "\n",
    "Метрики качества:\n",
    "Набор        | MSE        | MAE        | R2        \n",
    "---------------------------------------------\n",
    "Тренировочный | 6.5160 | 1.8329 | 0.9441\n",
    "Тестовый       | 6.9701 | 1.8391 | 0.9408\n",
    "\n",
    "Анализ переобучения:\n",
    "   Отношение MSE (тест/трен): 1.07\n",
    "Переобучение минимально.\n",
    "\n",
    "Важность признаков:\n",
    "   season      : 0.4790\n",
    "   month       : 0.4377\n",
    "   day_of_month: 0.0823\n",
    "   hour        : 0.0009\n",
    "\n",
    "Обновлённые метаданные с результатами сохранены: models/metadata_20251103_201232.json\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa0688",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<image src=\"models/model_evaluation_20251103_193243.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d8f6f",
   "metadata": {},
   "source": [
    "#### 5. Напишите bash-скрипт (pipeline.sh), последовательно запускающий все python-скрипты.\n",
    "\n",
    "`chmod +x pipeline.sh`\n",
    "\n",
    "[./pipeline.sh](pipeline.sh)\n",
    "\n",
    "<details>\n",
    "    <summary><b>Вывод</b></summary>\n",
    "\n",
    "```\n",
    "(.venv311) ➜  lab1 ./pipeline.sh     \n",
    "  train/data.csv: 6132 записей\n",
    "  test/data.csv:  2628 записей\n",
    "  Всего: 8760 записей (по ~90 дней × 24 часа × 4 сезона)\n",
    "Найдено тренировочных файлов: 2\n",
    "Найдено тестовых файлов: 2\n",
    "Объединено записей в train: 12264\n",
    "Объединено записей в test:  5256\n",
    "Сохранено:\n",
    "  - Тренировочные данные: data/preprocessed_data_train.csv (12264 записей)\n",
    "  - Тестовые данные:      data/preprocessed_data_test.csv (5256 записей)\n",
    "  - Параметры StandardScaler:    data/scaler_*.npy\n",
    "\n",
    "Столбцы в данных: ['day_of_month', 'month', 'hour', 'temperature', 'season', 'source']\n",
    "Масштабированные признаки: ['day_of_month', 'month', 'hour', 'season']\n",
    "Целевая переменная: temperature\n",
    "Загрузка тренировочных данных из: data/preprocessed_data_train.csv\n",
    "Загрузка тестовых данных из: data/preprocessed_data_test.csv\n",
    "\n",
    "Размер данных:\n",
    "   Тренировочные: 12264 записей\n",
    "   Тестовые:      5256 записей\n",
    "   Признаки: ['day_of_month', 'month', 'hour', 'season']\n",
    "   Целевая переменная: temperature\n",
    "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
    "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
    "Обучение завершено за 0:00:00.435639\n",
    "\n",
    "Модель сохранена: models/RandomForestRegressor_20251103_202125.joblib\n",
    "\\Метаданные сохранены: models/metadata_20251103_202125.json\n",
    "Автоматически выбран последний файл метаданных: models/metadata_20251103_202125.json\n",
    "\n",
    "Загружаем модель из models/RandomForestRegressor_20251103_202125.joblib\n",
    "Тренировочные данные из data/preprocessed_data_train.csv\n",
    "Тестовые данные из data/preprocessed_data_test.csv\n",
    "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
    "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
    "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
    "\n",
    "==================================================\n",
    "РЕЗУЛЬТАТЫ ТЕСТИРОВАНИЯ МОДЕЛИ\n",
    "==================================================\n",
    "\n",
    "Метрики качества:\n",
    "Набор        | MSE        | MAE        | R2        \n",
    "---------------------------------------------\n",
    "Тренировочный | 6.8607 | 1.8884 | 0.9410\n",
    "Тестовый       | 7.1630 | 1.9189 | 0.9391\n",
    "\n",
    "Анализ переобучения:\n",
    "   Отношение MSE (тест/трен): 1.04\n",
    "Переобучение минимально.\n",
    "\n",
    "Важность признаков:\n",
    "   month       : 0.4587\n",
    "   season      : 0.4585\n",
    "   day_of_month: 0.0819\n",
    "   hour        : 0.0009\n",
    "\n",
    "Обновлённые метаданные с результатами сохранены: models/metadata_20251103_202125.json\n",
    "готово\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
